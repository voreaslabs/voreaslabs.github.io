---
job_title: Scala & Spark Engineer
description: As a Spark engineer at VLI, you will design, develop, and optimize Spark applications for big data processing at large scale.
responsibilities:
  - Implement analytical algorithms in Spark
  - Use Spark to transform and process network data
  - Optimize and test Spark applications
  - Deploy and monitor applications in customersâ€™ environments
  - Assist other teams in the design and development of Spark applications
qualifications:
  required:
    - At least 3 years of experience developing Spark applications in PySpark and/or Scala
    - At least 2 years of experience programming in Scala
    - Excellent skills in deploying and monitoring distributed applications
    - Strong experience with Unix systems
    - Ability to obtain a DoD CAC
  preferred:
    - Experience with AWS (or other cloud service providers)
    - Good understanding of computer networks
    - Experience using infrastructure-as-code tools (e.g., Terraform)

---
